{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en3 to\n",
      "[nltk_data]     e:\\Anaconda\\nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Avg_words_per_sentence \n",
    "- Avg_syllables_per_word \n",
    "- Complex_word_percent   \n",
    "- Difficult_word_percent \n",
    "- Long_sent_percent      \n",
    "- Long_word_percent      \n",
    "- Avg_letters_per_word   \n",
    "- Comma_percent          \n",
    "- Proper_noun_percent    \n",
    "- Noun_percent           \n",
    "- Pronoun_percent        \n",
    "- Conj_percent           \n",
    "\n",
    "- Tokens            \n",
    "- Words             \n",
    "- Sentences         \n",
    "- N_words           \n",
    "- N_sentences       \n",
    "- N_syllables       \n",
    "- N_polysyllables   \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pyphen\n",
    "import benepar\n",
    "SPACY_MODEL = \"en_core_web_sm\"\n",
    "import en_core_web_sm\n",
    "\n",
    "def _get_words(x):\n",
    "    words = [token.text for token in x if token.is_punct != True]\n",
    "    return words\n",
    "\n",
    "def words_and_sentences(df):\n",
    "    nlp = spacy.load('en_core_web_sm', exclude=['parser', 'ner'])\n",
    "    nlp.add_pipe('sentencizer')    \n",
    "    df['Tokens'] = df['Text'].apply(lambda x: nlp(x))    \n",
    "    df['Words'] = df['Tokens'].apply(_get_words)    \n",
    "    df['Sentences'] = df['Tokens'].apply(lambda x: list(x.sents))    \n",
    "    df['N_words'] = df['Words'].apply(lambda x: len(x))    \n",
    "    df['N_sentences'] = df['Sentences'].apply(lambda x: len(x))    \n",
    "    df[\"Avg_words_per_sentence\"] = df[\"N_words\"] / df[\"N_sentences\"]    \n",
    "    return df\n",
    "\n",
    "def _count_hyphens(text, dic):\n",
    "    return dic.inserted(text).count(\"-\")\n",
    "\n",
    "def syllables(df):\n",
    "    dic = pyphen.Pyphen(lang='en_EN')\n",
    "    df[\"N_hyphens\"] = df[\"Text\"].apply(lambda x: _count_hyphens(x, dic))\n",
    "    df[\"N_syllables\"] = df[\"N_words\"] + df[\"N_hyphens\"]\n",
    "    df[\"Avg_syllables_per_word\"] = df[\"N_syllables\"] / df[\"N_words\"]\n",
    "    df.drop(columns=[\"N_hyphens\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def _get_dale_chall_easy_words():\n",
    "    easy_words = set()\n",
    "    with open(\"dale_chall_easy_word_list.txt\") as file:\n",
    "        lines = [line.rstrip('\\n') for line in file]\n",
    "        for line in lines:\n",
    "            easy_words.add(line.lower())\n",
    "    return easy_words\n",
    "\n",
    "\n",
    "def _get_num_difficult_words(text, easy_words):\n",
    "    n = 0\n",
    "    for word in text:\n",
    "        if word.lower() not in easy_words:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def difficult_words_pct(df):    \n",
    "    easy_words = _get_dale_chall_easy_words()    \n",
    "    df[\"Difficult_word_percent\"] = df[\"Words\"].apply(lambda x: _get_num_difficult_words(x, easy_words)) / df[\"N_words\"]    \n",
    "    return df\n",
    "\n",
    "def _count_polysyllables(words, dic):\n",
    "    n_complex = 0    \n",
    "    for word in words:\n",
    "        if dic.inserted(word).count(\"-\") >= 2:\n",
    "            n_complex += 1    \n",
    "    return n_complex\n",
    "\n",
    "\n",
    "def polysyllables(df):   \n",
    "    dic = pyphen.Pyphen(lang='en_EN')\n",
    "    df[\"N_polysyllables\"] = df[\"Words\"].apply(lambda x: _count_polysyllables(x, dic))    \n",
    "    return df\n",
    "\n",
    "def complex_words_pct(df):   \n",
    "    df[\"Complex_word_percent\"] = df[\"N_polysyllables\"] / df[\"N_words\"]    \n",
    "    return df\n",
    "\n",
    "def _get_n_long_sent(sentences):\n",
    "    n = 0\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 25:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "def long_sent_pct(df):   \n",
    "    df[\"Long_sent_percent\"] = df[\"Sentences\"].apply(_get_n_long_sent) / df[\"N_sentences\"]    \n",
    "    return df\n",
    "\n",
    "def _get_n_long_word(words):\n",
    "    n = 0\n",
    "    for word in words:\n",
    "        if len(word) > 8:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "def long_word_pct(df):   \n",
    "    df[\"Long_word_percent\"] = df[\"Words\"].apply(_get_n_long_word) / df[\"N_words\"]    \n",
    "    return df\n",
    "\n",
    "def _get_n_letters(words):\n",
    "    n = 0\n",
    "    for word in words:\n",
    "        n += len(word)\n",
    "    return n\n",
    "\n",
    "def avg_letters_per_word(df):   \n",
    "    df[\"Avg_letters_per_word\"] = df[\"Words\"].apply(_get_n_letters) / df[\"N_words\"]    \n",
    "    return df\n",
    "\n",
    "def _get_n_comma_sent(sentences):\n",
    "    n = 0\n",
    "    for sentence in sentences:\n",
    "        if str(sentence).find(\",\") != -1:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "def comma_pct(df):   \n",
    "    # get percentage\n",
    "    df[\"Comma_percent\"] = df[\"Sentences\"].apply(_get_n_comma_sent) / df[\"N_sentences\"]    \n",
    "    return df\n",
    "\n",
    "def _get_n_pos(tokens, pos_list):\n",
    "    n = 0\n",
    "    for token in tokens:\n",
    "        for pos in pos_list:\n",
    "            if token.pos_ == pos:\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "def pos_features(df):    \n",
    "    pos_list = [\"NOUN\", \"PROPN\"]\n",
    "    df[\"Noun_percent\"] = df[\"Tokens\"].apply(lambda x: _get_n_pos(x, pos_list)) / df[\"N_words\"]    \n",
    "    pos_list = [\"PROPN\"]\n",
    "    df[\"Proper_noun_percent\"] = df[\"Tokens\"].apply(lambda x: _get_n_pos(x, pos_list))/ df[\"N_words\"]    \n",
    "    pos_list = [\"PRON\"]\n",
    "    df[\"Pronoun_percent\"] = df[\"Tokens\"].apply(lambda x: _get_n_pos(x, pos_list)) / df[\"N_words\"]    \n",
    "    pos_list = [\"CONJ\", \"CCONJ\"]\n",
    "    df[\"Conj_percent\"] = df[\"Tokens\"].apply(lambda x: _get_n_pos(x, pos_list)) / df[\"N_words\"]    \n",
    "    return df\n",
    "\n",
    "def remove_aux_features(df):   \n",
    "    df.drop(columns=[\"Tokens\", \"Words\", \"Sentences\", \"N_words\", \"N_sentences\", \"N_syllables\", \"N_polysyllables\"], inplace=True)    \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "- NP_per_sent\n",
    "- VP_per_sent\n",
    "- PP_per_sent\n",
    "- SBAR_per_sent\n",
    "- SBARQ_per_sent\n",
    "- avg_NP_size\n",
    "- avg_VP_size\n",
    "- avg_PP_size\n",
    "- avg_parse_tree\n",
    "\n",
    "\"\"\"\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import benepar\n",
    "from benepar import BeneparComponent, NonConstituentException\n",
    "benepar.download('benepar_en3')\n",
    "\n",
    "def _parse_tree_height(sent):\n",
    "    \n",
    "    children = list(sent._.children)\n",
    "    if not children:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(_parse_tree_height(child) for child in children) + 1\n",
    "\n",
    "def _get_constituents(tokens):\n",
    "    const_counter = Counter()\n",
    "    const_lengths = defaultdict(list)\n",
    "\n",
    "    for sentence in tokens.sents:\n",
    "        for const in sentence._.constituents:\n",
    "            const_counter.update(Counter(const._.labels))\n",
    "            for label in const._.labels:\n",
    "                const_lengths[label].append(len(const))\n",
    "    \n",
    "    const_avgs = defaultdict(int)\n",
    "    for key in const_lengths.keys():\n",
    "        avg = 0.0\n",
    "        for length in const_lengths[key]: \n",
    "            avg += length\n",
    "        avg /= len(const_lengths[key])        \n",
    "        const_avgs[key] = avg         \n",
    "    return const_counter, const_avgs\n",
    "\n",
    "def _get_parse_tree_height(tokens):   \n",
    "    avg_parse_tree_height = 0.0    \n",
    "    for sentence in tokens.sents:\n",
    "        avg_parse_tree_height += _parse_tree_height(sentence)        \n",
    "    n_sentences = len(list(tokens.sents))\n",
    "    avg_parse_tree_height /= n_sentences    \n",
    "    return avg_parse_tree_height, n_sentences\n",
    "\n",
    "def _get_parse_tree_features(tokens):\n",
    "    const_counter, const_avgs = _get_constituents(tokens)\n",
    "    avg_parse_tree_height, n_sentences = _get_parse_tree_height(tokens)    \n",
    "    NP_per_sent = const_counter['NP'] / n_sentences\n",
    "    VP_per_sent = const_counter['VP'] / n_sentences\n",
    "    PP_per_sent = const_counter['PP'] / n_sentences\n",
    "    SBAR_per_sent = const_counter['SBAR'] / n_sentences\n",
    "    SBARQ_per_sent = const_counter['SBARQ'] / n_sentences\n",
    "    avg_NP_size = const_avgs['NP']\n",
    "    avg_VP_size = const_avgs['VP']\n",
    "    avg_PP_size = const_avgs['PP']\n",
    "    avg_parse_tree = avg_parse_tree_height    \n",
    "    return NP_per_sent, VP_per_sent, PP_per_sent, \\\n",
    "        SBAR_per_sent, SBARQ_per_sent, avg_NP_size, \\\n",
    "        avg_VP_size, avg_PP_size, avg_parse_tree\n",
    "    \n",
    "def parse_tree_features(df):\n",
    "    nlp = en_core_web_sm.load(disable=['ner'])\n",
    "    if spacy.__version__.startswith('2'):\n",
    "        nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "    else:\n",
    "        nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "    df['B_Tokens'] = df['Text'].apply(lambda x: nlp(x))\n",
    "    df['NP_per_sent'], df['VP_per_sent'], df['PP_per_sent'], \\\n",
    "    df['SBAR_per_sent'], df['SBARQ_per_sent'], df['avg_NP_size'], \\\n",
    "    df['avg_VP_size'], df['avg_PP_size'], df['avg_parse_tree'] = zip(*df['B_Tokens'].map(_get_parse_tree_features))\n",
    "    df.drop(columns=[\"B_Tokens\"], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\lib\\site-packages\\torch\\distributions\\distribution.py:44: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/TEST.csv\", index_col = 1) #导入目标数据集\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df = words_and_sentences(df)\n",
    "df = syllables(df)\n",
    "df = difficult_words_pct(df)\n",
    "df = polysyllables(df)\n",
    "df = complex_words_pct(df)\n",
    "df = long_sent_pct(df)\n",
    "df = long_word_pct(df)\n",
    "df = avg_letters_per_word(df)\n",
    "df = comma_pct(df)\n",
    "df = pos_features(df)\n",
    "df = remove_aux_features(df)\n",
    "df = parse_tree_features(df)\n",
    "df.to_csv(\"../data/TEST_with_features.csv\", encoding='utf-8') #特征保存路径"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def normalize(p, q):\n",
    "    p, q = np.asarray(p), np.asarray(q)\n",
    "    assert (p >= 0).all(), p\n",
    "    assert (q >= 0).all()\n",
    "    p, q = p / p.sum(), q / q.sum()\n",
    "    return p, q\n",
    "\n",
    "def JSD(p, q, base=2):\n",
    "    p, q = normalize(p, q)\n",
    "    m = 1. / 2 * (p + q)\n",
    "    return stats.entropy(p, m, base=base) / 2. + stats.entropy(q, m, base=base) / 2.\n",
    "\n",
    "def rnorm_sum_squares(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    assert x.shape == y.shape\n",
    "    numerator = np.sum(np.square(x - y))\n",
    "    denominator = np.sum(np.square(x) + np.square(y))\n",
    "    rnorm_ss = np.sqrt(numerator / denominator)\n",
    "    return rnorm_ss\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    metric = []\n",
    "    Rjsd=1-JSD(y_true, y_pred, base=2) \n",
    "    RRNSS = 1-rnorm_sum_squares(y_true, y_pred)\n",
    "    ndcg=ndcg_score([y_true], [y_pred])\n",
    "    metric.append(Rjsd)\n",
    "    metric.append(RRNSS)\n",
    "    metric.append(ndcg)\n",
    "    return metric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def grid_search_cv_for_ensembles(model, max_depth_values, n_estimators_values, X, y, scoring_function, k=5, verbose=0):   \n",
    "    best_score = 0.0\n",
    "    best_n_estimators = 1\n",
    "    best_max_depth = 1    \n",
    "    for max_depth in max_depth_values: \n",
    "        for n_estimators in n_estimators_values:            \n",
    "            kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "            fold = 1\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                model.set_hyperparams(max_depth, n_estimators)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                scores.append(scoring_function(y_test, y_pred))\n",
    "                fold += 1              \n",
    "            score = np.mean(scores)            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n_estimators = n_estimators\n",
    "                best_max_depth = max_depth\n",
    "    return best_max_depth, best_n_estimators\n",
    "\n",
    "def find_best_C(model, c_values, X, y, scoring_function, k=5, verbose=0):\n",
    "    best_score = 0.0\n",
    "    best_c = 1.0    \n",
    "    for c in c_values:             \n",
    "        kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "        fold = 1\n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model.set_hyperparams('linear', c)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            scores.append(scoring_function(y_test, y_pred))\n",
    "            fold += 1\n",
    "        score = np.mean(scores)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_c = c\n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def discretize(y_pred):    \n",
    "    for i in range(len(y_pred)):    \n",
    "        if y_pred[i] < 0.5:\n",
    "            y_pred[i] = 0.0\n",
    "        elif y_pred[i] < 1.5:\n",
    "            y_pred[i] = 1.0\n",
    "        elif y_pred[i] < 2.5:\n",
    "            y_pred[i] = 2.0\n",
    "        elif y_pred[i] < 3.5:\n",
    "            y_pred[i] = 3.0\n",
    "        else:\n",
    "            y_pred[i] = 4.0            \n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+Glove+feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class GloVeFeatXGBRegressor():\n",
    "    def __init__(self, embedding_size=300, n_estimators=100, max_depth=3, learning_rate=0.1):\n",
    "        # Load the GloVe word vector model\n",
    "        self.glove_file = '../gloveglove.6B.300d.txt'\n",
    "        self.glove_model = self.load_glove_model(self.glove_file)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.clf = XGBRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            learning_rate=self.learning_rate\n",
    "        )\n",
    "\n",
    "    def load_glove_model(self, glove_file):\n",
    "        model = {}\n",
    "        with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                split_line = line.strip().split()\n",
    "                word = split_line[0]\n",
    "                embedding = np.array([float(val) for val in split_line[1:]])\n",
    "                model[word] = embedding\n",
    "        return model\n",
    "\n",
    "    def _get_sentence_embedding(self, sentence):\n",
    "        vecs = [self.glove_model.get(word, np.zeros(self.embedding_size)) for word in sentence]\n",
    "        vecs = np.array(vecs)\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "    def train(self, X_train_text, X_train_feat, y_train):\n",
    "        X_train_vecs = np.array([self._get_sentence_embedding(sentence) for sentence in X_train_text])\n",
    "        X_train_vecs = np.hstack((X_train_vecs, X_train_feat))\n",
    "        self.clf.fit(X_train_vecs, y_train)\n",
    "\n",
    "    def predict(self, X_test_text, X_test_feat):\n",
    "        X_test_vecs = np.array([self._get_sentence_embedding(sentence) for sentence in X_test_text])\n",
    "        X_test_vecs = np.hstack((X_test_vecs, X_test_feat))\n",
    "        return discretize(self.clf.predict(X_test_vecs))\n",
    "\n",
    "    def evaluate(self, X_test_text, X_test_feat, y_test):\n",
    "        y_pred = self.predict(X_test_text, X_test_feat)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')        \n",
    "        return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class GloVeXGBRegressor():\n",
    "    def __init__(self, embedding_size=300, n_estimators=100, max_depth=3, learning_rate=0.1):\n",
    "        self.glove_file = '../glove/glove.6B.300d.txt'\n",
    "        self.glove_model = self.load_glove_model(self.glove_file)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.clf = XGBRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            learning_rate=self.learning_rate\n",
    "        )\n",
    "\n",
    "    def load_glove_model(self, glove_file):\n",
    "        model = {}\n",
    "        with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                split_line = line.strip().split()\n",
    "                word = split_line[0]\n",
    "                embedding = np.array([float(val) for val in split_line[1:]])\n",
    "                model[word] = embedding\n",
    "        return model\n",
    "\n",
    "    def _get_sentence_embedding(self, sentence):\n",
    "        sentence_str = ' '.join(sentence)\n",
    "        vecs = [self.glove_model[word] for word in sentence_str.split() if word in self.glove_model]\n",
    "        vecs = np.array(vecs)\n",
    "        return np.mean(vecs, axis=0)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        X_train_vecs = np.array([self._get_sentence_embedding(sentence) for sentence in X_train])\n",
    "        self.clf.fit(X_train_vecs, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_vecs = np.array([self._get_sentence_embedding(sentence) for sentence in X_test])\n",
    "        return discretize(self.clf.predict(X_test_vecs))\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        print(y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')        \n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "class XGBoost():    \n",
    "    def __init__(self, max_depth=30, n_estimators=200, save_model=False, use_saved_model=False, model_path='xgboost.pickle'):\n",
    "        self.model_path = model_path\n",
    "        self.n_estimators = n_estimators\n",
    "        self.save_model = save_model        \n",
    "        if use_saved_model:\n",
    "            with open(self.model_path, 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "        else:\n",
    "            self.model = xgboost = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, objective=\"reg:squarederror\")  \n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        if self.save_model:\n",
    "            with open(self.model_path, 'wb') as handle:\n",
    "                pickle.dump(self.model, handle)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return discretize(self.model.predict(X_test))\n",
    "        \n",
    "    def set_hyperparams(self, max_depth, n_estimators):    \n",
    "        self.model = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, objective=\"reg:squarederror\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test(feature,lable):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(feature,lable, test_size=0.2, random_state=42,stratify=lable)\n",
    "    X_train=np.array(X_train)\n",
    "    X_test=np.array(X_test)\n",
    "    y_train=np.array(y_train)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test=np.array(y_test)\n",
    "    y_test=y_test.ravel()\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_feature = pd.read_csv(\"../data/TEST_with_features.csv\")\n",
    "df =pd.DataFrame(DATA_feature)\n",
    "lable=df.iloc[:,0:1]\n",
    "feature=df.iloc[:,2:23]\n",
    "DATA_feature_train, DATA_feature_test, DATA_feature_trainy, DATA_feature_testy=get_train_test(feature,lable)\n",
    "\n",
    "DATA = pd.read_csv(\"../data/TEST.csv\")\n",
    "df =pd.DataFrame(DATA)\n",
    "lable=df.iloc[:,1:2]\n",
    "text=df.iloc[:,0:1]\n",
    "DATA_train, DATA_test, DATA_trainy, DATA_testy=get_train_test(text,lable)\n",
    "\n",
    "CEFR=pd.read_csv(\"../data/[CEFR]_test_with_features.csv\")\n",
    "CEFR_feature_testy=CEFR.iloc[:,1]   #label\n",
    "CEFR_feature_test=CEFR.iloc[:,2:23] #feature\n",
    "CEFR_feature_test=np.array(CEFR_feature_test)\n",
    "CEFR_test=CEFR.iloc[:,0]    #text\n",
    "CEFR_test=np.array(CEFR_test)\n",
    "\n",
    "CLEC=pd.read_csv(\"../data/[CLEC]_test_with_features.csv\")\n",
    "CLEC_feature_testy=CLEC.iloc[:,1]\n",
    "CLEC_feature_test=CLEC.iloc[:,2:23]\n",
    "CLEC_feature_test=np.array(CLEC_feature_test)\n",
    "CLEC_test=CLEC.iloc[:,0]\n",
    "CLEC_test=np.array(CLEC_test)\n",
    "\n",
    "CLOTH=pd.read_csv(\"../data/[CLOTH]_test_with_features.csv\")\n",
    "CLOTH_feature_testy=CLOTH.iloc[:,1]\n",
    "CLOTH_feature_test=CLOTH.iloc[:,2:23]\n",
    "CLOTH_feature_test=np.array(CLOTH_feature_test)\n",
    "CLOTH_test=CLOTH.iloc[:,0]\n",
    "CLOTH_test=np.array(CLOTH_test)\n",
    "\n",
    "OSP=pd.read_csv(\"../data/[OSP]_test_with_features.csv\")\n",
    "OSP_feature_testy=OSP.iloc[:,1]\n",
    "OSP_feature_test=OSP.iloc[:,2:23]\n",
    "OSP_feature_test=np.array(OSP_feature_test)\n",
    "OSP_test=OSP.iloc[:,0]\n",
    "OSP_test=np.array(OSP_test)\n",
    "\n",
    "NES=pd.read_csv(\"../data/[NES]_test_with_features.csv\")\n",
    "NES_feature_testy=NES.iloc[:,1]\n",
    "NES_feature_test=NES.iloc[:,2:23]\n",
    "NES_feature_test=np.array(NES_feature_test)\n",
    "NES_test=NES.iloc[:,0]\n",
    "NES_test=np.array(NES_test)\n",
    "\n",
    "RACE=pd.read_csv(\"../data/[RACE]_test_with_features.csv\")\n",
    "RACE_feature_testy=RACE.iloc[:,1]\n",
    "RACE_feature_test=RACE.iloc[:,2:23]\n",
    "RACE_feature_test=np.array(RACE_feature_test)\n",
    "RACE_test=RACE.iloc[:,0]\n",
    "RACE_test=np.array(RACE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Corpus Readability Assessment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests=[[CEFR_feature_test,  CEFR_feature_testy],\n",
    "       [CLEC_feature_test,  CLEC_feature_testy],\n",
    "       [CLOTH_feature_test, CLOTH_feature_testy],\n",
    "       [OSP_feature_test,   OSP_feature_testy],\n",
    "       [NES_feature_test,   NES_feature_testy],\n",
    "       [RACE_feature_test,  RACE_feature_testy]]\n",
    "\n",
    "scoring_function = lambda y_true, y_pred: spearmanr(y_true, y_pred)[0]\n",
    "max_depth_values = [5, 10, 15, 20, 30]\n",
    "n_estimators_values = [10, 50, 100, 200]\n",
    "max_depth, n_estimators = grid_search_cv_for_ensembles(XGBoost(), max_depth_values, n_estimators_values, DATA_feature_train, DATA_feature_trainy, scoring_function, k=3, verbose=1)\n",
    "xgboost = XGBoost(save_model=True)\n",
    "xgboost.fit(DATA_feature_train, DATA_feature_trainy)\n",
    "\n",
    "result = {}\n",
    "cor_metric = []\n",
    "for test_feature, y in tests:\n",
    "    y_pred = xgboost.predict(test_feature)\n",
    "    result['Numy'] = y\n",
    "    result['Numyp'] = y_pred\n",
    "    df = pd.DataFrame(result)\n",
    "    cor=print_metrics(y, y_pred)\n",
    "    cor_metric.append(cor)\n",
    "cor = pd.DataFrame(columns=['RJSD','RRNSS','NDCG'],index=['CEFR','CLEC','CLOTH','OSP','NES','RACE'],data=cor_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RJSD</th>\n",
       "      <th>RRNSS</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CEFR</th>\n",
       "      <td>0.983163</td>\n",
       "      <td>0.817967</td>\n",
       "      <td>0.964841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEC</th>\n",
       "      <td>0.896874</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.964119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOTH</th>\n",
       "      <td>0.918496</td>\n",
       "      <td>0.355605</td>\n",
       "      <td>0.986177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSP</th>\n",
       "      <td>0.836295</td>\n",
       "      <td>0.304971</td>\n",
       "      <td>0.876998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>0.984289</td>\n",
       "      <td>0.453482</td>\n",
       "      <td>0.976080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACE</th>\n",
       "      <td>0.940976</td>\n",
       "      <td>0.681214</td>\n",
       "      <td>0.996188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RJSD     RRNSS      NDCG\n",
       "CEFR   0.983163  0.817967  0.964841\n",
       "CLEC   0.896874  0.509737  0.964119\n",
       "CLOTH  0.918496  0.355605  0.986177\n",
       "OSP    0.836295  0.304971  0.876998\n",
       "NES    0.984289  0.453482  0.976080\n",
       "RACE   0.940976  0.681214  0.996188"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests=[[CEFR_test, CEFR_feature_testy],\n",
    "       [CLEC_test, CLEC_feature_testy],\n",
    "       [CLOTH_test, CLOTH_feature_testy],\n",
    "       [OSP_test, OSP_feature_testy],\n",
    "       [NES_test, NES_feature_testy],\n",
    "       [RACE_test, RACE_feature_testy]]\n",
    "\n",
    "model = GloVeXGBRegressor()\n",
    "model.train(DATA_train, DATA_trainy)\n",
    "\n",
    "cor_metric = []\n",
    "result = {}\n",
    "for X_test,y_test in tests:\n",
    "    y_pred = model.predict(X_test)\n",
    "    result['Numy'] = y_test\n",
    "    result['Numyp'] = y_pred\n",
    "    df = pd.DataFrame(result)\n",
    "    cor=print_metrics(y_test, y_pred)\n",
    "    cor_metric.append(cor)\n",
    "cor = pd.DataFrame(columns=['NDCG','RJSD','RRNSS'],index=['CEFR','CLEC','CLOTH','OSP','NES','RACE'], data=cor_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG</th>\n",
       "      <th>RJSD</th>\n",
       "      <th>RRNSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CEFR</th>\n",
       "      <td>0.955202</td>\n",
       "      <td>0.670231</td>\n",
       "      <td>0.918118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEC</th>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.634014</td>\n",
       "      <td>0.953194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOTH</th>\n",
       "      <td>0.994789</td>\n",
       "      <td>0.804894</td>\n",
       "      <td>0.985264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSP</th>\n",
       "      <td>0.793658</td>\n",
       "      <td>0.348196</td>\n",
       "      <td>0.827608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>0.959823</td>\n",
       "      <td>0.406672</td>\n",
       "      <td>0.934496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACE</th>\n",
       "      <td>0.994134</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.990361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NDCG      RJSD     RRNSS\n",
       "CEFR   0.955202  0.670231  0.918118\n",
       "CLEC   0.984127  0.634014  0.953194\n",
       "CLOTH  0.994789  0.804894  0.985264\n",
       "OSP    0.793658  0.348196  0.827608\n",
       "NES    0.959823  0.406672  0.934496\n",
       "RACE   0.994134  0.769969  0.990361"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost+glove+feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests=[[CEFR_test,  CEFR_feature_test,  CEFR_feature_testy],\n",
    "       [CLEC_test,  CLEC_feature_test,  CLEC_feature_testy],\n",
    "       [CLOTH_test, CLOTH_feature_test, CLOTH_feature_testy],\n",
    "       [OSP_test,   OSP_feature_test,   OSP_feature_testy],\n",
    "       [NES_test,   NES_feature_test,   NES_feature_testy],\n",
    "       [RACE_test,  RACE_feature_test,  RACE_feature_testy]]\n",
    "\n",
    "model = GloVeFeatXGBRegressor()\n",
    "model.train(DATA_train, DATA_feature_train, DATA_trainy)\n",
    "\n",
    "cor_metric = []\n",
    "result = {}\n",
    "for X_test,X_feat_test,y_test in tests:\n",
    "    y_pred = model.predict(X_test, X_feat_test)\n",
    "    result['Numy'] = y_test\n",
    "    result['Numyp'] = y_pred\n",
    "    df = pd.DataFrame(result)\n",
    "    cor=print_metrics(y_test, y_pred)\n",
    "    cor_metric.append(cor)    \n",
    "cor = pd.DataFrame(columns=['NDCG','RJSD','RRNSS'],index=['CEFR','CLEC','CLOTH','OSP','NES','RACE'], data=cor_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG</th>\n",
       "      <th>RJSD</th>\n",
       "      <th>RRNSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CEFR</th>\n",
       "      <td>0.966754</td>\n",
       "      <td>0.751987</td>\n",
       "      <td>0.951926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEC</th>\n",
       "      <td>0.952430</td>\n",
       "      <td>0.544423</td>\n",
       "      <td>0.969192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOTH</th>\n",
       "      <td>0.946969</td>\n",
       "      <td>0.434548</td>\n",
       "      <td>0.986852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSP</th>\n",
       "      <td>0.835041</td>\n",
       "      <td>0.304359</td>\n",
       "      <td>0.875594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES</th>\n",
       "      <td>0.986605</td>\n",
       "      <td>0.455790</td>\n",
       "      <td>0.977625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACE</th>\n",
       "      <td>0.962889</td>\n",
       "      <td>0.709252</td>\n",
       "      <td>0.996171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NDCG      RJSD     RRNSS\n",
       "CEFR   0.966754  0.751987  0.951926\n",
       "CLEC   0.952430  0.544423  0.969192\n",
       "CLOTH  0.946969  0.434548  0.986852\n",
       "OSP    0.835041  0.304359  0.875594\n",
       "NES    0.986605  0.455790  0.977625\n",
       "RACE   0.962889  0.709252  0.996171"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
